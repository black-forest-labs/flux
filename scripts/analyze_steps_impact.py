#!/usr/bin/env python3
"""
åˆ†æä¸åŒæ¨ç†æ­¥æ•°å¯¹Flux.1 devæ ¡å‡†æ•°æ®è´¨é‡çš„å½±å“

åŸºäºMixDQçš„æ€è·¯ï¼š
1. æ ¡å‡†æ•°æ®çš„ç›®æ ‡æ˜¯æ•è·æ¨¡å‹æ¿€æ´»çš„ç»Ÿè®¡åˆ†å¸ƒ
2. ä¸åŒæ¨ç†æ­¥æ•°ä¸‹çš„æ¿€æ´»åˆ†å¸ƒè¦†ç›–åº¦åˆ†æ
3. è®¡ç®—æˆæœ¬ vs æ ¡å‡†è´¨é‡çš„æƒè¡¡åˆ†æ
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple
import os
import argparse
from pathlib import Path

def analyze_activation_coverage(data_dict: Dict, step_counts: List[int]) -> Dict:
    """åˆ†æä¸åŒæ­¥æ•°ä¸‹çš„æ¿€æ´»è¦†ç›–åº¦"""
    
    results = {}
    
    for steps in step_counts:
        if f"flux_calib_{steps}_steps.pt" in data_dict:
            calib_data = data_dict[f"flux_calib_{steps}_steps.pt"]
            
            # åˆ†ææ¿€æ´»å¼ é‡çš„ç»Ÿè®¡åˆ†å¸ƒ
            xs = calib_data.get("xs", None)
            if xs is not None:
                # è®¡ç®—æ¿€æ´»å€¼çš„ç»Ÿè®¡æŒ‡æ ‡
                mean_vals = xs.mean(dim=(0, 2, 3, 4))  # è·¨batchå’Œç©ºé—´ç»´åº¦
                std_vals = xs.std(dim=(0, 2, 3, 4))
                min_vals = xs.min(dim=0)[0].flatten()
                max_vals = xs.max(dim=0)[0].flatten()
                
                # è®¡ç®—åˆ†å¸ƒç†µï¼ˆä½œä¸ºå¤šæ ·æ€§æŒ‡æ ‡ï¼‰
                hist_data = []
                for t in range(xs.size(0)):  # è·¨æ—¶é—´æ­¥
                    flat_vals = xs[t].flatten()
                    hist, _ = np.histogram(flat_vals.cpu().numpy(), bins=50, density=True)
                    hist = hist + 1e-10  # é¿å…log(0)
                    entropy = -np.sum(hist * np.log(hist))
                    hist_data.append(entropy)
                
                results[steps] = {
                    'mean_coverage': mean_vals.std().item(),  # å‡å€¼çš„å˜åŒ–èŒƒå›´
                    'std_coverage': std_vals.mean().item(),   # æ ‡å‡†å·®çš„å¹³å‡å€¼
                    'range_coverage': (max_vals.max() - min_vals.min()).item(),
                    'entropy_mean': np.mean(hist_data),
                    'entropy_std': np.std(hist_data),
                    'num_timesteps': xs.size(0),
                    'activation_shape': xs.shape
                }
    
    return results

def generate_test_data_different_steps(steps_list: List[int], output_dir: str) -> None:
    """ç”Ÿæˆä¸åŒæ­¥æ•°çš„æµ‹è¯•æ ¡å‡†æ•°æ®"""
    
    print(f"ğŸ§ª ç”Ÿæˆä¸åŒæ­¥æ•°çš„æµ‹è¯•æ•°æ®...")
    
    for steps in steps_list:
        output_path = os.path.join(output_dir, f"flux_calib_{steps}_steps.pt")
        
        if os.path.exists(output_path):
            print(f"âœ“ å·²å­˜åœ¨ï¼š{steps}æ­¥æ•°æ®")
            continue
            
        print(f"ğŸ“Š ç”Ÿæˆ{steps}æ­¥æ ¡å‡†æ•°æ®...")
        
        cmd = f"""python scripts/gen_flux_calib_data.py \
            --output_path {output_path} \
            --n_samples 8 \
            --height 256 \
            --width 256 \
            --num_steps {steps} \
            --seed 42"""
        
        os.system(cmd)

def plot_steps_analysis(results: Dict, output_dir: str) -> None:
    """ç»˜åˆ¶æ­¥æ•°åˆ†æç»“æœ"""
    
    steps = sorted(results.keys())
    
    # æå–æŒ‡æ ‡
    coverage_metrics = {
        'mean_coverage': [results[s]['mean_coverage'] for s in steps],
        'std_coverage': [results[s]['std_coverage'] for s in steps],
        'range_coverage': [results[s]['range_coverage'] for s in steps],
        'entropy_mean': [results[s]['entropy_mean'] for s in steps]
    }
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Flux.1 Dev: ä¸åŒæ¨ç†æ­¥æ•°å¯¹æ ¡å‡†æ•°æ®è´¨é‡çš„å½±å“', fontsize=16)
    
    # 1. æ¿€æ´»å‡å€¼è¦†ç›–åº¦
    axes[0, 0].plot(steps, coverage_metrics['mean_coverage'], 'bo-', linewidth=2, markersize=8)
    axes[0, 0].set_title('æ¿€æ´»å‡å€¼è¦†ç›–åº¦')
    axes[0, 0].set_xlabel('æ¨ç†æ­¥æ•°')
    axes[0, 0].set_ylabel('å‡å€¼å˜åŒ–èŒƒå›´')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].axvline(x=30, color='red', linestyle='--', alpha=0.7, label='æ¨è(30æ­¥)')
    axes[0, 0].legend()
    
    # 2. æ ‡å‡†å·®è¦†ç›–åº¦
    axes[0, 1].plot(steps, coverage_metrics['std_coverage'], 'go-', linewidth=2, markersize=8)
    axes[0, 1].set_title('æ¿€æ´»æ ‡å‡†å·®è¦†ç›–åº¦')
    axes[0, 1].set_xlabel('æ¨ç†æ­¥æ•°')
    axes[0, 1].set_ylabel('æ ‡å‡†å·®å¹³å‡å€¼')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].axvline(x=30, color='red', linestyle='--', alpha=0.7, label='æ¨è(30æ­¥)')
    axes[0, 1].legend()
    
    # 3. æ¿€æ´»èŒƒå›´è¦†ç›–åº¦
    axes[1, 0].plot(steps, coverage_metrics['range_coverage'], 'mo-', linewidth=2, markersize=8)
    axes[1, 0].set_title('æ¿€æ´»å€¼èŒƒå›´è¦†ç›–åº¦')
    axes[1, 0].set_xlabel('æ¨ç†æ­¥æ•°')
    axes[1, 0].set_ylabel('æœ€å¤§-æœ€å°å€¼èŒƒå›´')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].axvline(x=30, color='red', linestyle='--', alpha=0.7, label='æ¨è(30æ­¥)')
    axes[1, 0].legend()
    
    # 4. åˆ†å¸ƒç†µï¼ˆå¤šæ ·æ€§ï¼‰
    axes[1, 1].plot(steps, coverage_metrics['entropy_mean'], 'co-', linewidth=2, markersize=8)
    axes[1, 1].set_title('æ¿€æ´»åˆ†å¸ƒå¤šæ ·æ€§ (ç†µ)')
    axes[1, 1].set_xlabel('æ¨ç†æ­¥æ•°')
    axes[1, 1].set_ylabel('å¹³å‡ç†µå€¼')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].axvline(x=30, color='red', linestyle='--', alpha=0.7, label='æ¨è(30æ­¥)')
    axes[1, 1].legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'steps_analysis.png'), dpi=300, bbox_inches='tight')
    plt.show()

def calculate_efficiency_ratio(results: Dict) -> Dict:
    """è®¡ç®—æ•ˆç‡æ¯”ï¼šè´¨é‡æå‡ / è®¡ç®—æˆæœ¬å¢åŠ """
    
    steps = sorted(results.keys())
    base_steps = min(steps)  # ä»¥æœ€å°‘æ­¥æ•°ä¸ºåŸºå‡†
    
    efficiency = {}
    
    for i, current_steps in enumerate(steps[1:], 1):
        base_quality = results[base_steps]['entropy_mean']
        current_quality = results[current_steps]['entropy_mean']
        
        quality_improvement = (current_quality - base_quality) / base_quality
        cost_increase = (current_steps - base_steps) / base_steps
        
        efficiency_ratio = quality_improvement / cost_increase if cost_increase > 0 else 0
        
        efficiency[current_steps] = {
            'quality_improvement': quality_improvement * 100,  # ç™¾åˆ†æ¯”
            'cost_increase': cost_increase * 100,              # ç™¾åˆ†æ¯”  
            'efficiency_ratio': efficiency_ratio
        }
    
    return efficiency

def print_recommendations(results: Dict, efficiency: Dict) -> None:
    """æ‰“å°åŸºäºåˆ†æçš„æ¨è"""
    
    print("\n" + "="*60)
    print("ğŸ“Š Flux.1 Dev æ¨ç†æ­¥æ•°åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    print("\nğŸ¯ åŸºäºMixDQæ€è·¯çš„åˆ†æç»“æœï¼š")
    
    # æ‰¾åˆ°æœ€ä½³æ•ˆç‡ç‚¹
    best_efficiency_steps = max(efficiency.keys(), key=lambda x: efficiency[x]['efficiency_ratio'])
    
    print(f"\nğŸ“ˆ ä¸åŒæ­¥æ•°çš„è´¨é‡æŒ‡æ ‡ï¼š")
    for steps in sorted(results.keys()):
        entropy = results[steps]['entropy_mean']
        coverage = results[steps]['mean_coverage']
        print(f"  {steps}æ­¥: ç†µ={entropy:.3f}, è¦†ç›–åº¦={coverage:.3f}")
    
    print(f"\nâš¡ æ•ˆç‡åˆ†æï¼š")
    for steps in sorted(efficiency.keys()):
        eff = efficiency[steps]
        print(f"  {steps}æ­¥: è´¨é‡æå‡={eff['quality_improvement']:+.1f}%, "
              f"æˆæœ¬å¢åŠ ={eff['cost_increase']:+.1f}%, æ•ˆç‡æ¯”={eff['efficiency_ratio']:.3f}")
    
    print(f"\nğŸ¯ æ¨èç­–ç•¥ï¼š")
    print(f"  ğŸ’¡ æœ€ä½³æ•ˆç‡ç‚¹ï¼š{best_efficiency_steps}æ­¥")
    print(f"  ğŸ”¬ å¿«é€Ÿå¼€å‘ï¼š4-10æ­¥")
    print(f"  ğŸ­ ç”Ÿäº§åº”ç”¨ï¼š20-30æ­¥")
    print(f"  ğŸ”§ é«˜è´¨é‡ï¼š40-50æ­¥")
    
    print(f"\nğŸ“ MixDQå¯¹æ¯”åˆ†æï¼š")
    print(f"  â€¢ SDXL (50æ­¥æ¨¡å‹) â†’ ä½¿ç”¨30æ­¥æ ¡å‡† (60%)")
    print(f"  â€¢ Flux.1 dev (50æ­¥æ¨¡å‹) â†’ æ¨è30æ­¥æ ¡å‡† (60%)")
    print(f"  â€¢ ç­–ç•¥ä¸€è‡´æ€§ï¼šä¸¤è€…éƒ½é‡‡ç”¨çº¦60%çš„å®Œæ•´æ­¥æ•°")
    
    print(f"\nğŸ’¡ å®ç”¨å»ºè®®ï¼š")
    print(f"  â€¢ 30æ­¥èƒ½å¤Ÿè¦†ç›–å¤§éƒ¨åˆ†é‡è¦çš„å»å™ªé˜¶æ®µ")
    print(f"  â€¢ æ ¡å‡†é‡ç‚¹æ˜¯æ¿€æ´»ç»Ÿè®¡åˆ†å¸ƒï¼Œä¸æ˜¯å›¾åƒè´¨é‡")
    print(f"  â€¢ å¯ä»¥ä»20æ­¥å¼€å§‹ï¼Œæ ¹æ®é‡åŒ–ç»“æœè°ƒæ•´")
    print(f"  â€¢ å®Œæ•´50æ­¥ä»…åœ¨æœ€ç»ˆä¼˜åŒ–æ—¶è€ƒè™‘")

def main():
    parser = argparse.ArgumentParser(description="åˆ†æFlux.1 devä¸åŒæ¨ç†æ­¥æ•°çš„å½±å“")
    parser.add_argument("--output_dir", type=str, default="./steps_analysis", 
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--generate_data", action="store_true",
                       help="æ˜¯å¦ç”Ÿæˆæµ‹è¯•æ•°æ®")
    parser.add_argument("--steps_list", nargs='+', type=int, 
                       default=[4, 10, 20, 30, 40, 50],
                       help="è¦åˆ†æçš„æ­¥æ•°åˆ—è¡¨")
    
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.generate_data:
        generate_test_data_different_steps(args.steps_list, args.output_dir)
    
    # åŠ è½½ç°æœ‰æ•°æ®è¿›è¡Œåˆ†æ
    data_dict = {}
    for steps in args.steps_list:
        filepath = os.path.join(args.output_dir, f"flux_calib_{steps}_steps.pt")
        if os.path.exists(filepath):
            print(f"ğŸ“‚ åŠ è½½{steps}æ­¥æ•°æ®...")
            data_dict[f"flux_calib_{steps}_steps.pt"] = torch.load(filepath, map_location='cpu')
    
    if not data_dict:
        print("âŒ æœªæ‰¾åˆ°æ ¡å‡†æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨ --generate_data ç”Ÿæˆ")
        return
    
    # åˆ†ææ¿€æ´»è¦†ç›–åº¦
    print("\nğŸ” åˆ†ææ¿€æ´»è¦†ç›–åº¦...")
    results = analyze_activation_coverage(data_dict, args.steps_list)
    
    # è®¡ç®—æ•ˆç‡æ¯”
    print("ğŸ“Š è®¡ç®—æ•ˆç‡æ¯”...")
    efficiency = calculate_efficiency_ratio(results)
    
    # ç»˜åˆ¶åˆ†æå›¾
    print("ğŸ“ˆ ç”Ÿæˆåˆ†æå›¾è¡¨...")
    plot_steps_analysis(results, args.output_dir)
    
    # æ‰“å°æ¨è
    print_recommendations(results, efficiency)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨ï¼š{args.output_dir}")

if __name__ == "__main__":
    main() 